{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tanikin/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "#import matplotlib as plt\n",
    "from tdnn import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import kaldiio\n",
    "# from Mydataset import MyDataset\n",
    "print(sys.executable)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_io.BufferedReader' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-355ebd3ef312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_label.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: '_io.BufferedReader' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "f= open(\"train_label.pkl\",\"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class MyDataset(Data.Dataset):\n",
    "        def __init__(self,filepath,num_path):\n",
    "#             self.data = []\n",
    "            self.file = open(filepath,\"rb\")\n",
    "            with open(num_path,'rb') as f:\n",
    "                self.num = pickle.load(f)\n",
    "        def __len__(self):\n",
    "            return self.num\n",
    "        def __getitem__(self,index):\n",
    "            data,label =pickle.load(self.file)\n",
    "#             label = pickle.load(self.label)\n",
    "#             data = self.fopen.__next__()# 自定义transform()对训练数据进行预处理\n",
    "# #           data = list(zip(x,y))#transform(line)\n",
    "            return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train.pkl','rb') as f:\n",
    "#     X,y = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = -float('inf')#torch.log(torch.tensor(0,dtype= torch.float))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(filepath = 'train_.pkl',num_path = 'utt_num.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainloader = Data.DataLoader(dataset, shuffle=False, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 168])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, data in enumerate(trainloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    x,y= data\n",
    "    #inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    if i == 2:\n",
    "         break\n",
    "    #output= net(inputs)\n",
    "#     print(x)\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.close()\n",
    "dataset.label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " q= torch.tensor(X,dtype =torch.float,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tanikin/projct'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p = inputs.argmax(dim=2)\n",
    "# p.shape\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1680, 756, 24])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = q.mean(1)\n",
    "# std = q.std(1)\n",
    "# mean.shape\n",
    "# std.shape\n",
    "# wexs= torch.cat((mean,std),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean\n",
    "#wexs.shape\n",
    "# qq =q.unsqueeze(1)\n",
    "\n",
    "# x= F.unfold(qq,(5, 24),stride=(1,24), dilation=(1,1))\n",
    "# qq.shape\n",
    "# x = x.transpose(1,2)\n",
    "# TDNN.kernel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xxx =nn.Linear(24*5, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add_module('frame1', TDNN(input_dim=24, output_dim=512, context_size=5, dilation=1))#layer 1\n",
    "net.add_module('frame2', TDNN(input_dim=512, output_dim=512, context_size=3, dilation=2))#layer 2\n",
    "net.add_module('frame3', TDNN(input_dim=512, output_dim=512, context_size=3, dilation=3))#layer 3\n",
    "net.add_module('frame4', TDNN(input_dim=512, output_dim=512, context_size=1, dilation=1))#layer 4\n",
    "net.add_module('frame5', TDNN(input_dim=512, output_dim=1500, context_size=1, dilation=1))#layer 5\n",
    "net.add_module('pool',StatsPooling())#pooling\n",
    "net.add_module('segment6',Segment(input_dim=3000, output_dim=512))#segment1\n",
    "net.add_module('segment7',Segment(input_dim=512, output_dim=512))#segment2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = torch.load('final_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = net.state_dict()\n",
    "state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
    "model_dict.update(state_dict)\n",
    "net.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in save_model.items():\n",
    "#     if k in model_dict.keys():\n",
    "#         print(k)\n",
    "net.add_module('softmax',Softmax(input_dim = 512, output_dim = len(y[0])))#softmax\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (frame1): TDNN(\n",
       "    (kernel): Linear(in_features=120, out_features=512, bias=True)\n",
       "    (nonlinearity): ReLU()\n",
       "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (frame2): TDNN(\n",
       "    (kernel): Linear(in_features=1536, out_features=512, bias=True)\n",
       "    (nonlinearity): ReLU()\n",
       "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (frame3): TDNN(\n",
       "    (kernel): Linear(in_features=1536, out_features=512, bias=True)\n",
       "    (nonlinearity): ReLU()\n",
       "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (frame4): TDNN(\n",
       "    (kernel): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (nonlinearity): ReLU()\n",
       "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (frame5): TDNN(\n",
       "    (kernel): Linear(in_features=512, out_features=1500, bias=True)\n",
       "    (nonlinearity): ReLU()\n",
       "    (bn): BatchNorm1d(1500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pool): StatsPooling()\n",
       "  (segment6): Segment(\n",
       "    (kernel): Linear(in_features=3000, out_features=512, bias=True)\n",
       "    (nonlinearity): ReLU()\n",
       "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (segment7): Segment(\n",
       "    (kernel): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (nonlinearity): ReLU()\n",
       "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (softmax): Softmax(\n",
       "    (kernel): Linear(in_features=512, out_features=462, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sdsd = net()\n",
    "\n",
    "#if os.path.exists('trained_net1025.pth'):\n",
    "        #net.load_state_dict(torch.load('trained_net1025.pth'))\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([409, 258,  75, 140, 354,  38, 257, 364, 451, 426, 457, 300, 329,  89,\n",
      "         90, 341, 399, 207, 326, 189])\n"
     ]
    }
   ],
   "source": [
    "#pp = p.unsqueeze(1)\n",
    "#pp =F.unfold(X[0],(5,24),stride=1,dilation=1)\n",
    "inputs = inputs.type(torch.float)\n",
    "inputs.requires_grad_(True)\n",
    "out= net(inputs)\n",
    "# out\n",
    "labels = labels.type(torch.float)\n",
    "print(out.argmin(dim=1))\n",
    "val = out.argmin(dim=1)\n",
    "ll = labels.argmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([409, 258,  75, 140, 354,  38, 257, 364, 451, 426, 457, 300, 329,  89,\n",
       "          90, 341, 399, 207, 326, 189]),\n",
       " tensor([460, 460, 460, 460, 460, 460, 460, 460, 460, 460, 461, 461, 461, 461,\n",
       "         461, 461, 461, 461, 461, 461]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val,ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(len((val))):\n",
    "    if val[i]==ll[i]:\n",
    "        count += 1\n",
    "    \n",
    "# frame1 = TDNN(input_dim=24, output_dim=512, context_size=5, dilation=1)\n",
    "# frame2 = TDNN(input_dim=512, output_dim=512, context_size=3, dilation=2)\n",
    "# frame3 = TDNN(input_dim=512, output_dim=512, context_size=3, dilation=3)\n",
    "# frame4 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=1)\n",
    "# frame5 = TDNN(input_dim=512, output_dim=1500, context_size=1, dilation=1)\n",
    "# pool = StatsPooling()\n",
    "# segment6 = Segment(input_dim=3000, output_dim=512)\n",
    "# segment7 =Segment(input_dim=512, output_dim=512)\n",
    "print(count/len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# layer1 = frame1(q)# input TDNN(batch, seq_len, input_features)\n",
    "# layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer2 = frame2(layer1)\n",
    "# layer2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer3 = frame3(layer2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer4 = frame4(layer3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer5 = frame5(layer4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "# layer6 = pool(layer5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se = segment6(layer6)\n",
    "# se2 = segment7(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se = segment6(layer6)\n",
    "# se2 = segment7(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  sdsd = net(q)\n",
    "# # sdsd\n",
    "# layer5.shape\n",
    "# # layer6.shape\n",
    "# #mean = layer5.mean(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1= torch.tensor(X[5:10],dtype =torch.float,requires_grad=True)\n",
    "# target= torch.tensor(y[0:5],dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target1= torch.tensor(y[5:10],dtype= torch.float)\n",
    "# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sdsd = net(q)\n",
    "# loss = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# l = (loss(sdsd,target))\n",
    "# #output\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.02)\n",
    "# net.zero_grad()\n",
    "# l.backward()\n",
    "# optimizer.step()\n",
    "# print(l)\n",
    "\n",
    "# # for param in net.parameters():\n",
    "# #     print(param[0])\n",
    "\n",
    "# print('=================================')    \n",
    "\n",
    "# out = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     sdsd1 = net(q1)\n",
    "#     loss = nn.MSELoss(reduction='sum')\n",
    "\n",
    "#     l = (loss(sdsd1,target1))\n",
    "#     #output\n",
    "#     optimizer = optim.Adam(net.parameters(), lr=0.02)\n",
    "#     net.zero_grad()\n",
    "#     l.backward()\n",
    "#     optimizer.step()\n",
    "#     print('loss is %.4f'%(l))\n",
    "\n",
    "# # for param in net.parameters():\n",
    "# #     print(param[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 5\n",
    "for epoch in range(1,num_epoch+1):\n",
    "    dataset = MyDataset(filepath = 'train_.pkl',num_path = 'utt_num.pkl')\n",
    "    trainloader = Data.DataLoader(dataset, shuffle=False, batch_size=10)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        input_, label = data\n",
    "        #inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        #output= net(inputs).cuda()\n",
    "        inputs = input_.type(torch.float)\n",
    "        inputs.requires_grad_(True)\n",
    "        labels = label.type(torch.float)\n",
    "        \n",
    "        \n",
    "    dataset.file.close()\n",
    "#         output = net(inputs)\n",
    "#         loss = nn.MSELoss(reduction='sum')\n",
    "        #l = (torch.sum(output*labels))\n",
    "#         a = torch.max(output)\n",
    "#         optimizer = optim.Adam(net.parameters(), lr=0.02)\n",
    "#         net.zero_grad()\n",
    "#         l.backward()\n",
    "#         optimizer.step()    \n",
    "#     print('epoch %d, loss: %f' % (epoch, l.item()))\n",
    "#     if (epoch % 50) ==0:\n",
    "#         torch.save(net.state_dict(),'trained_net.pth')\n",
    "#         print('model saved, epoch: %d'%(epoch))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x00'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e2ce6b038433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final.raw'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mkaldiweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#torch.load('final.raw')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x00'."
     ]
    }
   ],
   "source": [
    "with open('final.raw','rb') as f:\n",
    "      kaldiweights = pickle.load(f)\n",
    "#torch.load('final.raw')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
